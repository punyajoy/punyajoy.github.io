[{"authors":["admin"],"categories":null,"content":"Punyajoy Saha is a PMRF research scholar in the Department of Computer Science and Engineering at IIT Kharagpur, West Bengal. Currently, he is doing research under the supervision of Prof. Animesh Mukherjee. He is also a member of the research group CNeRG.\nResearch - His current research interests lie in the intersection of computational social science and natural language processing. He is working in developing better human-in-the-loop mitigation strategies for hate speech and other forms of harmful speech like fear speech. The collection of his efforts as well as his colleagues towards the goal of creating a more inclusive and accepting online environment is present at this website\nReviewer assignment - AAAI 2021, ACL 2020, ACL-IJCNLP 2021, EACL 2021, AAAI 2022, AAAI 2023\nTeaching Assistantship - AI and Ethics,Spring 2021 (CS60016), Algorithms-1,Autumn 2021 (CS21003), AI and Ethics,Spring 2022 (CS60016), Information retrieval 2023 (CS60092)\nOutside Teaching Assitantship - As a part of PMRF deliverables, I am also a teaching assistant for the NPTEL-NLP course, videos are uploaded weekly here and taking a course on \u0026ldquo;Programming in C\u0026rdquo; in Hijli College, Kharagpur (materials to be updated soon).\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Punyajoy Saha is a PMRF research scholar in the Department of Computer Science and Engineering at IIT Kharagpur, West Bengal. Currently, he is doing research under the supervision of Prof. Animesh Mukherjee. He is also a member of the research group CNeRG.\nResearch - His current research interests lie in the intersection of computational social science and natural language processing. He is working in developing better human-in-the-loop mitigation strategies for hate speech and other forms of harmful speech like fear speech.","tags":null,"title":"Punyajoy Saha","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":["Mithun Das","Saurabh Kumar Pandey","Shivansh Sethi","Punyajoy Saha","Animesh Mukherjee"],"categories":null,"content":"","date":1707609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1707609600,"objectID":"df397c2bc955b156642552a7180c1910","permalink":"/publication/eacl_2024/","publishdate":"2024-02-11T00:00:00Z","relpermalink":"/publication/eacl_2024/","section":"publication","summary":"With the rise of online abuse, the NLP community has begun investigating the use of neural architectures to generate counterspeech that can counter the vicious tone of such abusive speech and dilute/ameliorate their rippling effect over the social network. However, most of the efforts so far have been primarily focused on English. To bridge the gap for low-resource languages such as Bengali and Hindi, we create a benchmark dataset of 5,062 abusive speech/counterspeech pairs, of which 2,460 pairs are in Bengali and 2,602 pairs are in Hindi. We implement several baseline models considering various interlingual transfer mechanisms with different configurations to generate suitable counterspeech to set up an effective benchmark. We observe that the monolingual setup yields the best performance. Further, using synthetic transfer, language models can generate counterspeech to some extent; specifically, we notice that transferability is better when languages belong to the same language family.","tags":null,"title":"Low-Resource Counterspeech Generation for Indic Languages: The Case of Bengali and Hindi","type":"publication"},{"authors":["Sarthak Roy","Ashish Harshavardhan","Animesh Mukherjee","Punyajoy Saha"],"categories":null,"content":"","date":1702598400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1702598400,"objectID":"13966d8ec79455fb7e960d83d44d18c4","permalink":"/publication/emnlp_2023/","publishdate":"2023-12-15T00:00:00Z","relpermalink":"/publication/emnlp_2023/","section":"publication","summary":"Recently efforts have been made by social media platforms as well as researchers to detect hateful or toxic language using large language models. However, none of these works aim to use explanation, additional context and victim community information in the detection process. We utilise different prompt variation, input information and evaluate large language models in zero shot setting (without adding any in-context examples). We select three large language models (GPT-3.5, text-davinci and Flan-T5) and three datasets - HateXplain, implicit hate and ToxicSpans. We find that on average including the target information in the pipeline improves the model performance substantially (~20-30%) over the baseline across the datasets. There is also a considerable effect of adding the rationales/explanations into the pipeline (~10-20%) over the baseline across the datasets. In addition, we further provide a typology of the error cases where these large language models fail to (i) classify and (ii) explain the reason for the decisions they take. Such vulnerable points automatically constitute 'jailbreak' prompts for these models and industry scale safeguard techniques need to be developed to make the models robust against such prompts.","tags":null,"title":"Probing LLMs for hate speech detection: strengths and vulnerabilities","type":"publication"},{"authors":["punyajoy"],"categories":null,"content":"","date":1690983000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690983000,"objectID":"2b3cf367e7df81e7c4158fa0f131102e","permalink":"/talk/cybervsr_talk/","publishdate":"2021-07-31T08:15:38+05:30","relpermalink":"/talk/cybervsr_talk/","section":"talk","summary":"This talk explores the impact of harmful speech, particularly fear speech, on social media platforms such as Gab and Whatsapp in the US and India. Comparing it with hate speech, the analysis highlights the need for enhanced moderation policies to address the nuanced challenges of these expressions, advocating for a safer and more inclusive digital space.","tags":[],"title":"Echoes of Fear: Unraveling the Presence of Fear Speech in Social Media Platforms @CyberVSR","type":"talk"},{"authors":["[Punyajoy Saha](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Punyajoy+Saha\u0026btnG=)","Divyanshu Sheth","Kushal Kedia","[Binny Mathew](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Binny+Mathew\u0026btnG=)","[Animesh Mukherjee](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Animesh+Mukherjee\u0026btnG=)"],"categories":null,"content":"Link to the supplementary file\nMain contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1689379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689379200,"objectID":"625c22ea2fbcf8348d93e7f781d2b333","permalink":"/publication/saha2023ecai/","publishdate":"2023-07-15T00:00:00Z","relpermalink":"/publication/saha2023ecai/","section":"publication","summary":"Abusive language is a concerning problem in online social media. Past research on detecting abusive language covers different platforms, languages, demographies, etc. However, models trained using these datasets do not perform well in cross-domain evaluation settings. To overcome this, a common strategy is to use a few samples from the target domain to train models to get better performance in that domain (cross-domain few-shot training). However, this might cause the models to overfit the artefacts of those samples. A compelling solution could be to guide the models toward rationales, i.e., spans of text that justify the text’s label. This method has been found to improve model performance in the in-domain setting across various NLP tasks. In this paper, we propose RGFS (Rationale-Guided Few-Shot Classification) for abusive language detection. We first build a multitask learning setup to jointly learn rationales, targets, and labels, and find a significant improvement of 6% macro F1 on the rationale detection task over training solely rationale classifiers. We introduce two rationale-integrated BERT-based architectures (the RGFS models) and evaluate our systems over five different abusive language datasets, finding that in the few-shot classification setting, RGFS-based models outperform baseline models by about 7% in macro F1 scores and perform competitively to models finetuned on other source domains. Furthermore, RGFS-based models outperform LIME/SHAP-based approaches in terms of plausibility and are close in performance in terms of faithfulness","tags":["Our papers","counterspeech","English","Generation"],"title":"Rationale-Guided Few-Shot Classification to Detect Abusive Language","type":"publication"},{"authors":["[Punyajoy Saha](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Punyajoy+Saha\u0026btnG=)","[Kiran Garimella](https://scholar.google.co.in/citations?user=PH96F4oAAAAJ\u0026hl=en\u0026oi=ao)","Narla Komal Kalyana","Saurabh Kumar Pandeya","Pauras Mangesh Meher","[Binny Mathew](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Binny+Mathew\u0026btnG=)","[Animesh Mukherjee](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Animesh+Mukherjee\u0026btnG=)"],"categories":null,"content":"Significance Existential fear has always been a concern across human history and even transcends to the rest of the animal world. This fear is so deeply ingrained that even the slightest “knock” to it could spark a violent conflict among different groups. Here, we demonstrate how social media platforms are used to extensively mediate elements of existential fear as fear speech posts. Their nontoxic and argumentative nature makes them appealing to even benign users who in turn contribute to their wide prevalence by resharing, liking, and replying to them. Remarkably, this prevalence is far stronger than the more well-known hate speech posts. Our work necessitates consolidated moderation efforts and awareness campaigns to mitigate the harmful effects of fear speech.\nMain contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1685750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685750400,"objectID":"b7f46d9fcea133052ec8982e2e09b902","permalink":"/publication/saha2022pnas/","publishdate":"2023-06-03T00:00:00Z","relpermalink":"/publication/saha2022pnas/","section":"publication","summary":"Recently, social media platforms are heavily moderated to prevent the spread of online hate speech, which is usually fertile in toxic words and is directed toward an individual or a community. Owing to such heavy moderation, newer and more subtle techniques are being deployed. One of the most striking among these is fear speech. Fear speech, as the name suggests, attempts to incite fear about a target community. Although subtle, it might be highly effective, often pushing communities toward a physical conflict. Therefore, understanding their prevalence in social media is of paramount importance. This article presents a large-scale study to understand the prevalence of 400K fear speech and over 700K hate speech posts collected from Gab.com. Remarkably, users posting a large number of fear speech accrue more followers and occupy more central positions in social networks than users posting a large number of hate speech. They can also reach out to benign users more effectively than hate speech users through replies, reposts, and mentions. This connects to the fact that, unlike hate speech, fear speech has almost zero toxic content, making it look plausible. Moreover, while fear speech topics mostly portray a community as a perpetrator using a (fake) chain of argumentation, hate speech topics hurl direct multitarget insults, thus pointing to why general users could be more gullible to fear speech. Our findings transcend even to other platforms (Twitter and Facebook) and thus necessitate using sophisticated moderation policies and mass awareness to combat fear speech..","tags":["Our papers","counterspeech","English","Generation"],"title":"On the rise of fear speech in online social media","type":"publication"},{"authors":["Mithun Das","Rohit Raj","Punyajoy Saha","Binny Mathew","Manish Gupta","Animesh Mukherjee"],"categories":null,"content":"","date":1685664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685664000,"objectID":"cf723d23e556abeee8a9bedf0d7104f0","permalink":"/publication/icwsm_2023/","publishdate":"2023-06-02T00:00:00Z","relpermalink":"/publication/icwsm_2023/","section":"publication","summary":"Hate speech has become one of the most significant issues inmodern society, having implications in both the online and theoffline world. Due to this, hate speech research has recentlygained a lot of traction. However, most of the work has pri-marily focused on text media with relatively little work on im-ages and even lesser on videos. Thus, early stage automatedvideo moderation techniques are needed to handle the videosthat are being uploaded to keep the platform safe and healthy.With a view to detect and remove hateful content from thevideo sharing platforms, our work focuses on hate video de-tection using multi-modalities. To this end, we curate∼43hours of videos from BitChute and manually annotate themas hate or non-hate, along with the frame spans which couldexplain the labelling decision. To collect the relevant videoswe  harnessed  search  keywords  from  hate  lexicons.  We  ob-serve various cues in images and audio of hateful videos. Fur-ther, we build deep learning multi-modal models to classifythe hate videos and observe that using all the modalities ofthe videos improves the overall hate speech detection perfor-mance (accuracy=0.798, macro F1-score=0.790) by∼5.7%compared to the best uni-modal model in terms of macro F1score. In summary, our work takes the first step toward under-standing and modeling hateful videos on video hosting plat-forms such as BitChute.","tags":["Our Papers","Detection","Abusive language","Multi-Modal"],"title":"HateMM: A Multi-Modal Dataset for Hate Video Classification","type":"publication"},{"authors":["Piush Aggarwal","Pranit Chawla","Mithun Das","Punyajoy Saha","Binny Mathew","Torsten Zesch","Animesh Mukherjee"],"categories":null,"content":"","date":1683158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1683158400,"objectID":"a6c4975aaca24cbaf4f04665d44c0462","permalink":"/publication/www_2023/","publishdate":"2023-05-04T00:00:00Z","relpermalink":"/publication/www_2023/","section":"publication","summary":"Exploiting social media to spread hate has tremendously increased over the years. Lately, multi-modal hateful content such as memes has drawn relatively more traction than uni-modal content. Moreover, the availability of implicit content payloads makes them fairly challenging to be detected by existing hateful meme detection systems. In this paper, we present a use case study to analyze such systems’ vulnerabilities against external adversarial attacks. We fnd that even very simple perturbations in uni-modal and multimodal settings performed by humans with little knowledge about the model can make the existing detection models highly vulnerable. Empirically, we fnd a noticeable performance drop of as high as 10% in the macro-F1 score for certain attacks. As a remedy, we attempt to boost the model’s robustness using contrastive learning as well as an adversarial training-based method - VILLA. Using an ensemble of the above two approaches, in two of our high resolution datasets, we are able to (re)gain back the performance to a large extent for certain attacks. We believe that ours is a frst step toward addressing this crucial problem in an adversarial setting and would inspire more such investigations in the future.","tags":null,"title":"HateProof: Are Hateful Meme Detection Systems really Robust?","type":"publication"},{"authors":["punyajoy"],"categories":null,"content":"Important updates  Slides can be found here Video of the tutorial can be found here!!  Contributions and achievements  Our papers are accepted in top conferences/journals like PNAS, NeurIPS, LREC, AAAI, IJCAI, WWW, ECML-PKDD, CSCW, ICWSM, HyperText and WebSci. Link to the papers here We have open sourced our codes and datasets under a single github organisation - hate-alert for the future research in this domain We have stored different transformers models in huggingface.co. Link to hatealert organisation Dataset from our recent accepted paper in AAAI - \u0026ldquo;Hatexplain:A Benchmark Dataset for Explainable Hate Speech Detection\u0026rdquo; is also stored in the huggingface datsets forum We also participate in several hate speech shared tasks, winning many of them - hatealert@URDU_SOC,hatealert@DLTEACL, hateminers@AMI, hatemonitors@HASOC and coming under 1% in hatealert@Hatememe detection by Facebook AI. Notion page containing hate speech papers.  Tutorial Outline Outline of the Tutorial\n Introduction (25 mins) Analysis (40 mins)  Prevalence of hate speech. Targets of hate speech. Effects of hate speech. Effect of offline events.   Detection (40 mins)  Summary of different datasets.  Unimodal. Multimodal.   Earlier detection models. Current detection models . Multimodal and multilingual hate speech. Challenge.  Evaluation. Explainability. Bias.     Mitigation (40 mins).  Counterspeech campaigns. Banning and suspending users. Counterspeech detection. Counterspeech generation. Effect of counter speech.   Demo (15 mins). Future Challenge (10 mins).  About the Organizers Punyajoy Saha is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interests lies in the nexus of social computing and natural language processing. More about him can be found here.\nBinny Mathew is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in computational social science and natural language processing. More about him can be found here.\nMithun Das is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interests lie in computational social science and natural language processing. More about him can be found here.\nAnimesh Mukherjee is an Associate Professor at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in natural language processing, information retrieval and AI and ethics. More about him can be found here.\n","date":1679886000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679886000,"objectID":"fbf42f5ff83c66033310fd856df00eb9","permalink":"/talk/wsdm_tutorial/","publishdate":"2021-03-02T08:15:38+05:30","relpermalink":"/talk/wsdm_tutorial/","section":"talk","summary":"In this translation style tutorial presented at WSDM 2023, we present an exposition of hate speech detection and mitigation and also lay down future path for hate speech research","tags":[],"title":"Hate speech: Detection, Mitigation and Beyond @WSDM","type":"talk"},{"authors":["punyajoy"],"categories":null,"content":"","date":1674140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1674140400,"objectID":"167b9457d9d1f3a5ddb9647c5c81c0e0","permalink":"/talk/claws_talk/","publishdate":"2021-07-31T08:15:38+05:30","relpermalink":"/talk/claws_talk/","section":"talk","summary":"Social media has become an integral part of our everyday life. It allows the rapid dissemination of information and opinions. However, sometimes people use such media to express a range of phenomenon that often overlap and intersect, and includes a variety of types of speech that cause different harms. Such speech is collectively known as harmful speech. In this talk, I will focus on how we can use enablers to tackle the problem with the help of moderators. These enablers include detection systems capable of identifying various forms of harmful messages, explainers to add explainability in such systems and mitigation systems to regulate spread of harmful speech. All these systems are aimed at reducing the efforts of moderators, thereby making the moderation pipelines more efficient.","tags":[],"title":"Enabling moderation of harmful content in online social media platforms@CLAWS group","type":"talk"},{"authors":["[Vikram Gupta](https://scholar.google.com/citations?user=jNjvdEgAAAAJ\u0026hl=en\u0026oi=ao)","Sumegh Roychowdhury","[Mithun Das](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Mithun+Das\u0026btnG=)","[Somnath Banerjee](https://scholar.google.co.in/citations?user=X5Zh5BwAAAAJ\u0026hl=en)","[Punyajoy Saha](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Punyajoy+Saha\u0026btnG=)","[Binny Mathew](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Binny+Mathew\u0026btnG=)","Hastagiri Prakash Vanchinathan","[Animesh Mukherjee](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Animesh+Mukherjee\u0026btnG=)"],"categories":null,"content":"Main contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1664928000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664928000,"objectID":"8a5671640dfc3ea7745a995f7126989f","permalink":"/publication/neurips_2022/","publishdate":"2022-10-05T00:00:00Z","relpermalink":"/publication/neurips_2022/","section":"publication","summary":"Due to the sheer volume of online hate, the AI and NLP communities have started building models to detect such hateful content. Recently, multilingual hate is a major emerging challenge for automated detection where code-mixing or more than one language have been used for conversation in social media. Typically, hate speech detection models are evaluated by measuring their performance on the held-out test data  using metrics such as accuracy and F1-score. While these metrics are useful, it becomes difficult to identify using them where the model is failing, and how to resolve it. To enable more targeted diagnostic insights of such multilingual hate speech models, we introduce a set of functionalities for the purpose of evaluation. We have been inspired to design this kind of functionalities based on real-world conversation on social media. Considering Hindi as a base language, we craft test cases for each functionality. We name our evaluation dataset HateCheckHIn. To illustrate the utility of these functionalities , we test state-of-the-art transformer based m-BERT model and the Perspective API.","tags":["Our Papers","Detection","Abusive language","Indic","Multilingual"],"title":"Multilingual Abusive Comment Detection at Scale for Indic Languages","type":"publication"},{"authors":["punyajoy"],"categories":null,"content":"This talk was in the monthly meeting of CredCo.\n","date":1652340600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652340600,"objectID":"61a94cce94d303665196933c85c2ff78","permalink":"/talk/credco_talk/","publishdate":"2021-07-31T08:15:38+05:30","relpermalink":"/talk/credco_talk/","section":"talk","summary":"Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance.  In this paper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT model toward more polite, detoxified, and emotionally laden counterspeech. We generate counterspeech using three datasets and observe significant improvement across different attribute scores. The politeness and detoxification scores increased by around 15% and 6% respectively, while the emotion in the counterspeech increased by at least 10% across all the datasets. We also experiment with triple-attribute control and observe significant improvement over single attribute results when combining complementing attributes, e.g., politeness, joyfulness and detoxification. In all these experiments, the relevancy of the generated text does not deteriorate due to the application of these controls","tags":[],"title":"Generating counter speech with CounterGeDi@CredCo","type":"talk"},{"authors":["Punyajoy Saha","Kanishk Singh","Adarsh Kumar","Binny Mathew","Animesh Mukherjee"],"categories":null,"content":"Link to the supplementary file\n","date":1651276800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651276800,"objectID":"640dbe07a3e7339de801947e5064a58a","permalink":"/publication/ijcai_2022/","publishdate":"2022-04-30T00:00:00Z","relpermalink":"/publication/ijcai_2022/","section":"publication","summary":"Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance.  In this paper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT model toward more polite, detoxified, and emotionally laden counterspeech. We generate counterspeech using three datasets and observe significant improvement across different attribute scores. The politeness and detoxification scores increased by around 15% and 6% respectively, while the emotion in the counterspeech increased by at least 10% across all the datasets. We also experiment with triple-attribute control and observe significant improvement over single attribute results when combining complementing attributes, e.g., politeness, joyfulness and detoxification. In all these experiments, the relevancy of the generated text does not deteriorate due to the application of these controls.","tags":["Our papers","counterspeech","English","Generation"],"title":"CounterGeDi: A controllable approach to generate polite, detoxified and emotional counterspeech","type":"publication"},{"authors":["[Mithun Das](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Mithun+Das\u0026btnG=)","[Punyajoy Saha](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Punyajoy+Saha\u0026btnG=)","[Binny Mathew](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Binny+Mathew\u0026btnG=)","[Animesh Mukherjee](https://scholar.google.com/citations?view_op=search_authors\u0026hl=en\u0026mauthors=Animesh+Mukherjee\u0026btnG=)"],"categories":null,"content":"Main contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1650931200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650931200,"objectID":"46a7128fb25682d69a826585cb35a599","permalink":"/publication/lrec_2022/","publishdate":"2022-04-26T00:00:00Z","relpermalink":"/publication/lrec_2022/","section":"publication","summary":"Due to the sheer volume of online hate, the AI and NLP communities have started building models to detect such hateful content. Recently, multilingual hate is a major emerging challenge for automated detection where code-mixing or more than one language have been used for conversation in social media. Typically, hate speech detection models are evaluated by measuring their performance on the held-out test data  using metrics such as accuracy and F1-score. While these metrics are useful, it becomes difficult to identify using them where the model is failing, and how to resolve it. To enable more targeted diagnostic insights of such multilingual hate speech models, we introduce a set of functionalities for the purpose of evaluation. We have been inspired to design this kind of functionalities based on real-world conversation on social media. Considering Hindi as a base language, we craft test cases for each functionality. We name our evaluation dataset HateCheckHIn. To illustrate the utility of these functionalities , we test state-of-the-art transformer based m-BERT model and the Perspective API.","tags":["Our Papers","Detection","Abusive language","Hindi"],"title":"HateCheckHIn: Evaluating Hindi Hate Speech Detection Models","type":"publication"},{"authors":["hate-alert"],"categories":null,"content":"Important updates  Slides can be found here  Contributions and achievements  Our papers are accepted in top conferences like AAAI, WWW, CSCW, ICWSM, WebSci. Link to the papers here We have open sourced our codes and datasets under a single github organisation - hate-alert for the future research in this domain We have stored different transformers models in huggingface.co. Link to hatealert organisation Dataset from our recent accepted paper in AAAI - \u0026ldquo;Hatexplain:A Benchmark Dataset for Explainable Hate Speech Detection\u0026rdquo; is also stored in the huggingface datsets forum We also participate in several hate speech shared tasks, winning many of them - hatealert@URDU_SOC,hatealert@DLTEACL, hateminers@AMI, hatemonitors@HASOC and coming under 1% in hatealert@Hatememe detection by Facebook AI. Notion page containing hate speech papers.  Tutorial Outline In this translation style tutorial, we present an exposition of hate speech detection and mitigation in three steps. The following section presents a detailed plan for the tutorial:-\n Introduction (15 min)- This section will cover the scentific interest in hate speech and various definitions of hate speech. This section will help you understand the outline and what to take home from this tutorial. Analysis (20 min)- In this section, we analyze the spread of hate speech in online social media platforms like Twitter, Facebook, Gab etc. We observe that hate speech is spreading through online communities at an alarming rate. These hateful users are well connected among themselves and are reaching a wider audience. This case is more severe in moderation free platforms like Gab, Bitchute etc. The targets of such hate vary. These include the Muslims, Jews, Africans etc. This section is further divided into the following parts  Spread of hate speech Effects of hate speech Targets of hate speech   Detection (20 min)- Hate speech detection is a challenging task. We now have several datasets available based on different criterias language, domain, modalities etc.Several models ranging from simple Bag of Words to complex ones like BERT have been used for the task. The task performance seems to be improving over time, however, there are issues like generalizability, bias and explainability of the models. This section is further divided into  Different datasets. Earlier detection models Current detection models (based on transformers) Multimodal and Multilingual hate speech Hate user detection Challenge: Evaluation, Explainability and Bias   Mitigation (20 min)- To deter the spread of hate speech, organizations have adopted several policies. These include the general policies like deletion of posts and/or accounts, shadow banning to softer approaches like counterspeech. Policies like banning/deletion seem to be effective in some cases, but there are issues of violation of freedom of speech. Recent research have started looking into automated generation of counterspeech as well.  Banning and suspending users Counter speech detection Counter speech generation Challenges: Generation pitfalls, Moderation effects   Road to the future (15 min)- We end this tutorial with covering the summary of the challenges and road to the future for hate speech research.  Summary of challenges Branches and extensions of hate speech. Connections to offline violence. Guidelines for building better dataset. Adapting to newer events and platforms.    About the Organizers Punyajoy Saha is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interests lies in the nexus of social computing and natural language processing. More about him can be found here.\nBinny Mathew is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in computational social science and natural language processing. More about him can be found here.\nMithun Das is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interests lie in computational social science and natural language processing. More about him can be found here.\nAnimesh Mukherjee is an Associate Professor at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in natural language processing, information retrieval and AI and ethics. More about him can be found here.\n","date":1645633800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645633800,"objectID":"4f165e148f3686d5c9fbeae7ac9fe80d","permalink":"/talk/aaai_tutorial/","publishdate":"2021-03-02T08:15:38+05:30","relpermalink":"/talk/aaai_tutorial/","section":"talk","summary":"In this translation style tutorial presented at AAAI 2022, we present an exposition of hate speech detection and mitigation and also lay down future path for hate speech research","tags":[],"title":"Hate speech: Detection, Mitigation and Beyond @AAAI","type":"talk"},{"authors":["punyajoy"],"categories":null,"content":"","date":1644498000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644498000,"objectID":"7e6c7e68cd9c5929bcf8a353c10e7f99","permalink":"/talk/arcs_talk/","publishdate":"2021-02-11T08:15:38+05:30","relpermalink":"/talk/arcs_talk/","section":"talk","summary":"In this paper, we perform the first large scale study on fear speech across thousands of public WhatsApp groups discussing politics in India. We curate a new dataset and try to characterize fear speech from this dataset. We observe that users writing fear speech messages use various events and symbols to create the illusion of fear among the reader about a target community. Fear speech messages tend to spread faster and could potentially go undetected by classifiers built to detect traditional toxic speech due to their low toxic nature.","tags":[],"title":"Fear speech in Indian Whatsapp groups @ARCS","type":"talk"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our paper “Short is the Road that Leads from Fear to Hate\u0026rdquo;:Fear Speech in Indian WhatsApp Groups” will be presented at ARCS conference. Joint work with Binny Mathew, Kiran Garimella and Animesh mukherjee. Check this twitter_link to know more. Paper and code is out.\n","date":1639161000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639161000,"objectID":"4af116d7be4e23154801be7946bb3857","permalink":"/post/arcs_2022_accepted/","publishdate":"2021-12-11T00:00:00+05:30","relpermalink":"/post/arcs_2022_accepted/","section":"post","summary":"Our paper “Short is the Road that Leads from Fear to Hate\u0026rdquo;:Fear Speech in Indian WhatsApp Groups” will be presented at ARCS conference. Joint work with Binny Mathew, Kiran Garimella and Animesh mukherjee. Check this twitter_link to know more. Paper and code is out.","tags":[],"title":"Paper on Fear speech in Indian public Whatsapp groups to be presented at ARCS 2022","type":"post"},{"authors":["Mithun Das","Somnath Banerjee","Punyajoy Saha"],"categories":null,"content":"","date":1637971200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637971200,"objectID":"b49d1f046def5a93b6be2aae6d955d76","permalink":"/publication/fire_2021/","publishdate":"2021-11-27T00:00:00Z","relpermalink":"/publication/fire_2021/","section":"publication","summary":"Online hatred is a growing concern on many social media platforms. To address this issue, different social media platforms have introduced moderation policies for such content. They also employ moderators who can check the posts violating moderation policies and take appropriate action. Academicians in the abusive language research domain also perform various studies to detect such content better. Although there is extensive research in abusive language detection in English, there is a lacuna in abusive language detection in low resource languages like Hindi, Urdu etc. In this FIRE 2021 shared task - HASOC- Abusive and Threatening language detection in Urdu the organizers propose an abusive language detection dataset in Urdu along with threatening language detection. In this paper, we explored several machine learning models such as XGboost, LGBM, m-BERT based models for abusive and threatening content detection in Urdu based on the shared task. We observed the Transformer model specifically trained on abusive language dataset in Arabic helps in getting the best performance. Our model came First for both abusive and threatening content detection with an F1scoreof 0.88 and 0.54, respectively.","tags":null,"title":"Abusive and Threatening Language Detection in Urdu using Boosting based and BERT based models: A Comparative Approach","type":"publication"},{"authors":["Somnath Banerjee","Mithun Das","Punyajoy Saha"],"categories":null,"content":"","date":1637971200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1637971200,"objectID":"c44f6da14766d1406455dca14cec7e37","permalink":"/publication/fire_2021_1/","publishdate":"2021-11-27T00:00:00Z","relpermalink":"/publication/fire_2021_1/","section":"publication","summary":"Hate speech is considered to be one of the major issues currently plaguing online social media. Repeated and repetitive exposure to hate speech has been shown to create physiological effects on the target users. Thus, hate speech, in all its forms, should be addressed on these platforms in order to maintain good health. In this paper, we explored several Transformer based machine learning models for the detection of hate speech and offensive content in English and Indo-Aryan languages at FIRE 2021. We explore several models such as mBERT, XLMR-large, XLMR-base by team name Super Mario. Our models came 2nd position in Code-Mixed Data set (Macro F1: 0.7107), 2nd position in Hindi two-class classification(Macro F1: 0.7797), 4th in English four-class category (Macro F1: 0.8006) and 12th in English two-class category (Macro F1: 0.6447)","tags":null,"title":"Exploring Transformer Based Models to Identify Hate Speech and Offensive Content in English and Indo-Aryan Languages","type":"publication"},{"authors":["punyajoy"],"categories":null,"content":"","date":1632747600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632747600,"objectID":"fc14e72c76b6ae9e2e8bfa9fe6901741","permalink":"/talk/crrash_talk/","publishdate":"2021-03-02T08:15:38+05:30","relpermalink":"/talk/crrash_talk/","section":"talk","summary":"In this invited talk, I talk about how we can automate counterspeech generation and assist the moderators working in this domain. I also talk about the possible pitfalls and challlenges about automating it.","tags":[],"title":"Automating Counterspeech: Challenges and Opportunities","type":"talk"},{"authors":["Punyajoy Saha"],"categories":[],"content":"I have been invited to present my research on counter speech and its challenges. More on the event can be found here http://www.crassh.cam.ac.uk/events/29885\n","date":1632162600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632162600,"objectID":"cc2d6c188f33236904ae3b04a8518b3b","permalink":"/post/talk_on_counterspeech/","publishdate":"2021-09-21T00:00:00+05:30","relpermalink":"/post/talk_on_counterspeech/","section":"post","summary":"I have been invited to present my research on counter speech and its challenges. More on the event can be found here http://www.crassh.cam.ac.uk/events/29885","tags":[],"title":"Invited talk in  Understanding and Automating Counterspeech workshop organised by CRASSH","type":"post"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our paper \u0026ldquo;You too Brutus! Trapping Hateful Users in Social Media: Challenges, Solutions \u0026amp; Insights\u0026rdquo; was won the Ted Nelson Newcomer Award at ACM Hypertext 2021. The award nomination is present here : https://ht.acm.org/ht2021/programme/best-paper-awards/\n","date":1630521000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630521000,"objectID":"9f7be42bd9792ab489dbf2ac5d767d4f","permalink":"/post/acmht_2021/","publishdate":"2021-09-02T00:00:00+05:30","relpermalink":"/post/acmht_2021/","section":"post","summary":"Our paper \u0026ldquo;You too Brutus! Trapping Hateful Users in Social Media: Challenges, Solutions \u0026amp; Insights\u0026rdquo; was won the Ted Nelson Newcomer Award at ACM Hypertext 2021. The award nomination is present here : https://ht.acm.org/ht2021/programme/best-paper-awards/","tags":[],"title":"Our paper hateful user detection paper has won the highly presitgious Ted Nelson Newcomer Award at ACM Hypertext 2021.","type":"post"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our team hate-alert has ranked 1st in both subtasks in Abusive and Threatening Language Detection for Tweets in Urdu. The two subtasks are The task is composed of two binary classification subtasks: (A) abusive intent; (B) threatening intent. Paper and code will be out soon. Check the leaderboard : https://ods.ai/tracks/open-science-soc2021/competitions/urdu-hack-soc2021/leaderboard\n","date":1630348200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630348200,"objectID":"85a2c672150e9d54e006d5e0c54ae93b","permalink":"/post/opensoc_2021/","publishdate":"2021-08-31T00:00:00+05:30","relpermalink":"/post/opensoc_2021/","section":"post","summary":"Our team hate-alert has ranked 1st in both subtasks in Abusive and Threatening Language Detection for Tweets in Urdu. The two subtasks are The task is composed of two binary classification subtasks: (A) abusive intent; (B) threatening intent. Paper and code will be out soon. Check the leaderboard : https://ods.ai/tracks/open-science-soc2021/competitions/urdu-hack-soc2021/leaderboard","tags":[],"title":" 1st in both subtasks of Abusive and Threatening Language Detection for Tweets in Urdu: Abusive Language Detection at FIRE 2021","type":"post"},{"authors":["Mithun Das","Punyajoy Saha","Ritam Dutt","Pawan Goyal","Animesh Mukherjee","Binny Mathew"],"categories":null,"content":"Main contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1627603200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627603200,"objectID":"0618cd1a17e95bb9d622104960c1d4d3","permalink":"/publication/acmht_2021/","publishdate":"2021-07-30T00:00:00Z","relpermalink":"/publication/acmht_2021/","section":"publication","summary":" Hate speech is regarded as one of the crucial issues plaguing the online social media. The current literature on hate speech detection leverages primarily the textual content to find hateful posts and subsequently identify hateful users. However, this methodology disregards the social connections between users. In this paper, we run a detailed exploration of the problem space and investigate an array of models ranging from purely textual to graph based to finally semi-supervised techniques using Graph Neural Networks (GNN) that utilize both textual and graph-based features. We run exhaustive experiments on two datasets -- Gab, which is loosely moderated and Twitter, which is strictly moderated. Overall the AGNN model achieves 0.791 macro F1-score on the Gab dataset and 0.780 macro F1-score on the Twitter dataset using only 5% of the labeled instances, considerably outperforming all the other models including the fully supervised ones. We perform detailed error analysis on the best performing text and graph based models and observe that hateful users have unique network neighborhood signatures and the AGNN model benefits by paying attention to these signatures. This property, as we observe, also allows the model to generalize well across platforms in a zero-shot setting. Lastly, we utilize the best performing GNN model to analyze the evolution of hateful users and their targets over time in Gab. ","tags":null,"title":"You too Brutus! Trapping Hateful Users in Social Media: Challenges, Solutions \u0026 Insights","type":"publication"},{"authors":["punyajoy"],"categories":null,"content":"","date":1627390800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627390800,"objectID":"5dd998e376f3fe5b0c4046436acff22f","permalink":"/talk/ic2s2_talk/","publishdate":"2021-07-31T08:15:38+05:30","relpermalink":"/talk/ic2s2_talk/","section":"talk","summary":"In this paper, we perform the first large scale study on fear speech across thousands of public WhatsApp groups discussing politics in India. We curate a new dataset and try to characterize fear speech from this dataset. We observe that users writing fear speech messages use various events and symbols to create the illusion of fear among the reader about a target community. Fear speech messages tend to spread faster and could potentially go undetected by classifiers built to detect traditional toxic speech due to their low toxic nature.","tags":[],"title":"Fear speech in Indian Whatsapp groups@1C2S2","type":"talk"},{"authors":["hate-alert"],"categories":null,"content":"Important updates  Slides can be found here Video of the tutorial can be found here!!  Contributions and achievements  Our papers are accepted in top conferences like AAAI, WWW, CSCW, ICWSM, WebSci. Link to the papers here We have open sourced our codes and datasets under a single github organisation - hate-alert for the future research in this domain We have stored different transformers models in huggingface.co. Link to hatealert organisation Dataset from our recent accepted paper in AAAI - \u0026ldquo;Hatexplain:A Benchmark Dataset for Explainable Hate Speech Detection\u0026rdquo; is also stored in the huggingface datsets forum We also participate in several hate speech shared tasks, winning many of them - hatealert@DLTEACL, hateminers@AMI, hatemonitors@HASOC and coming under 1% in hatealert@Hatememe detection by Facebook AI. Notion page containing hate speech papers.  Tutorial Outline In this translation style tutorial, we present an exposition of hate speech detection and mitigation in three steps. The following section presents a detailed plan for the tutorial:-\n Introduction (15 min)- This section will cover the scentific interest in hate speech and various definitions of hate speech. This section will help you understand the outline and what to take home from this tutorial. Analysis (20 min)- In this section, we analyze the spread of hate speech in online social media platforms like Twitter, Facebook, Gab etc. We observe that hate speech is spreading through online communities at an alarming rate. These hateful users are well connected among themselves and are reaching a wider audience. This case is more severe in moderation free platforms like Gab, Bitchute etc. The targets of such hate vary. These include the Muslims, Jews, Africans etc. This section is further divided into the following parts  Spread of hate speech Effects of hate speech Targets of hate speech   Detection (20 min)- Hate speech detection is a challenging task. We now have several datasets available based on different criterias language, domain, modalities etc.Several models ranging from simple Bag of Words to complex ones like BERT have been used for the task. The task performance seems to be improving over time, however, there are issues like generalizability, bias and explainability of the models.  Different datasets. This section is further divided into Earlier detection models Current detection models (based on transformers) Multimodal and Multilingual hate speech Hate user detection Challenge: Evaluation, Explainability and Bias   Mitigation (20 min)- To deter the spread of hate speech, organizations have adopted several policies. These include the general policies like deletion of posts and/or accounts, shadow banning to softer approaches like counterspeech. Policies like banning/deletion seem to be effective in some cases, but there are issues of violation of freedom of speech. Recent research have started looking into automated generation of counterspeech as well.  Banning and suspending users Counter speech detection Counter speech generation Challenges: Generation pitfalls, Moderation effects   Road to the future (15 min)- We end this tutorial with covering the summary of the challenges and road to the future for hate speech research.  Summary of challenges Branches and extensions of hate speech. Connections to offline violence. Guidelines for building better dataset. Adapting to newer events and platforms.    About the Organizers Punyajoy Saha is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interests lies in the nexus of social computing and natural language processing. More about him can be found here.\nBinny Mathew is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in computational social science and natural language processing. More about him can be found here.\nMithun Das is a PhD scholar at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interests lie in computational social science and natural language processing. More about him can be found here.\nPawan Goyal is an Associate Professor at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in natural language processing and text mining. More about him can be found here.\nKiran Garimella is the first IDSS postdoctoral fellow to receive a Hammer Fellowship, pioneers research into the spread of rumors and misinformation on closed platforms such as WhatsApp, a popular encrypted messaging service with millions of users worldwide. More about him can be found here.\nAnimesh Mukherjee is an Associate Professor at the Department of Computer Science and Engineering, Indian Institute of Technology, Kharagpur (India). His research interest lies in natural language processing, information retrieval and AI and ethics. More about him can be found here.\n","date":1623070800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623070800,"objectID":"9eb46877140873b0b88d4801198a69bb","permalink":"/talk/icwsm_tutorial/","publishdate":"2021-03-02T08:15:38+05:30","relpermalink":"/talk/icwsm_tutorial/","section":"talk","summary":"In this translation style tutorial presented at ICWSM 2021, we present an exposition of hate speech detection and mitigation and also lay down future path for hate speech research","tags":[],"title":"Hate speech: Detection, Mitigation and Beyond @ICWSM","type":"talk"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our paper “Short is the Road that Leads from Fear to Hate\u0026rdquo;:Fear Speech in Indian WhatsApp Groups” will be presented at IC2S2 conference. Joint work with Binny Mathew, Kiran Garimella and Animesh mukherjee. Check this twitter_link to know more. Paper and code is out.\n","date":1620930600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620930600,"objectID":"8e0525eee062e562b4c24ad5bada8dab","permalink":"/post/ic2s2_2021-accepted/","publishdate":"2021-05-14T00:00:00+05:30","relpermalink":"/post/ic2s2_2021-accepted/","section":"post","summary":"Our paper “Short is the Road that Leads from Fear to Hate\u0026rdquo;:Fear Speech in Indian WhatsApp Groups” will be presented at IC2S2 conference. Joint work with Binny Mathew, Kiran Garimella and Animesh mukherjee. Check this twitter_link to know more. Paper and code is out.","tags":[],"title":"Paper on Fear speech in Indian public Whatsapp groups to be presented at IC2S2 2021","type":"post"},{"authors":["Debjoy Saha","Naman Paharia","Debajit Chakraborty","Punyajoy Saha","Animesh Mukherjee"],"categories":null,"content":"Main contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1613692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613692800,"objectID":"13b5071f8e5c14b526794eae651aaa67","permalink":"/publication/eacl_2021/","publishdate":"2021-02-19T00:00:00Z","relpermalink":"/publication/eacl_2021/","section":"publication","summary":"Social media often acts as breeding grounds for different forms of offensive content. For low resource languages like Tamil, the situation is more complex due to the poor performance of multilingual or language-specific models and lack of proper benchmark datasets. Based on this shared task, Offensive Language Identification in Dravidian Languages at EACL 2021, we present an exhaustive exploration of different transformer models, We also provide a genetic algorithm technique for ensembling different models. Our ensembled models trained separately for each language secured the first position in Tamil, the second position in Kannada, and the first position in Malayalam sub-tasks. The models and codes are provided.","tags":null,"title":"Hate-Alert@ DravidianLangTech-EACL2021: Ensembling strategies for Transformer-based Offensive language Detection","type":"publication"},{"authors":["Punyajoy Saha"],"categories":[],"content":"We are going to give a tutorial on \u0026ldquo;Hatespeech: Detection, Mitigation and beyond\u0026rdquo;. Please check the website for more details.\n","date":1613154600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1613154600,"objectID":"6a9f7f487d50b739eb4d4e44d77d6288","permalink":"/post/icwsm2021_tutorial_accepted/","publishdate":"2021-02-13T00:00:00+05:30","relpermalink":"/post/icwsm2021_tutorial_accepted/","section":"post","summary":"We are going to give a tutorial on \u0026ldquo;Hatespeech: Detection, Mitigation and beyond\u0026rdquo;. Please check the website for more details.","tags":[],"title":"Tutorial on 'Hate speech- Detection, Mitigation and beyond' accepted at ICWSM 2021","type":"post"},{"authors":["Punyajoy Saha","Binny Mathew","Kiran Garimella","Animesh Mukherjee"],"categories":null,"content":"","date":1612828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612828800,"objectID":"fb85ff0e47f3b79f28829d8bef21cd49","permalink":"/publication/www_2021/","publishdate":"2021-02-09T00:00:00Z","relpermalink":"/publication/www_2021/","section":"publication","summary":"WhatsApp is the most popular messaging app in the world. Due to its popularity, WhatsApp has become a powerful and cheap tool for political campaigning being widely used during the 2019 Indian general election, where it was used to connect to the voters on a large scale. Along with the campaigning, there have been reports that WhatsApp has also become a breeding ground for harmful speech against various protected groups and religious minorities. Many such messages attempt to instil fear among the population about a specific (minority) community. According to research on inter-group conflict, such \"fear speech\" messages could have a lasting impact and might lead to real offline violence. In this paper, we perform the first large scale study on fear speech across thousands of public WhatsApp groups discussing politics in India. We curate a new dataset and try to characterize fear speech from this dataset. We observe that users writing fear speech messages use various events and symbols to create the illusion of fear among the reader about a target community. We build models to classify fear speech and observe that current state-of-the-art NLP models do not perform well at this task. Fear speech messages tend to spread faster and could potentially go undetected by classifiers built to detect traditional toxic speech due to their low toxic nature. Finally, using a novel methodology to target users with Facebook ads, we conduct a survey among the users of these WhatsApp groups to understand the types of users who consume and share fear speech. We believe that this work opens up new research questions that are very different from tackling hate speech which the research community has been traditionally involved in.","tags":null,"title":"Short is the Road that Leads from Fear to Hate: Fear Speech in Indian WhatsApp Groups","type":"publication"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our team hate-alert has ranked 1st, 2nd and 1st in offensive language detection in Tamil, Kannada and Malayalam respectively. Amazing effort by the students Debjoy Saha,Naman Paharia and Debajit Chakraborty. Paper and code will be out soon.\n","date":1610735400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610735400,"objectID":"f48f265e10bc8ffadb8024e3a47fa271","permalink":"/post/eacl2021_workshop/","publishdate":"2021-01-16T00:00:00+05:30","relpermalink":"/post/eacl2021_workshop/","section":"post","summary":"Our team hate-alert has ranked 1st, 2nd and 1st in offensive language detection in Tamil, Kannada and Malayalam respectively. Amazing effort by the students Debjoy Saha,Naman Paharia and Debajit Chakraborty. Paper and code will be out soon.","tags":[],"title":" 1st, 2nd and 1st in offensive language detection in Tamil, Kannada and Malayalam respectively in Dravidian workshop at EACL2021","type":"post"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our paper “Short is the Road that Leads from Fear to Hate\u0026rdquo;:Fear Speech in Indian WhatsApp Groups” has been accepted as full paper at The Webconference -21 . Joint work with Binny Mathew, Kiran Garimella and Animesh mukherjee. Check this twitter_link to know more. Paper and code is out.\n","date":1610649000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610649000,"objectID":"e0114489ab2aea1be0f983ad01191626","permalink":"/post/www2021_accepted/","publishdate":"2021-01-15T00:00:00+05:30","relpermalink":"/post/www2021_accepted/","section":"post","summary":"Our paper “Short is the Road that Leads from Fear to Hate\u0026rdquo;:Fear Speech in Indian WhatsApp Groups” has been accepted as full paper at The Webconference -21 . Joint work with Binny Mathew, Kiran Garimella and Animesh mukherjee. Check this twitter_link to know more. Paper and code is out.","tags":[],"title":"Paper on Fear speech in Indian public Whatsapp groups is accepted in WWW 2021","type":"post"},{"authors":["Poojitha Maheshappa","Binny Mathew","Punyajoy Saha"],"categories":null,"content":"Main contributions Coming soon\nLimitations Coming soon\nFuture Directions Coming soon\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"12680f070a0fc16a4d8149afe7cc4bbd","permalink":"/publication/cods_comad_2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/cods_comad_2021/","section":"publication","summary":" With the increasing cases of online hate speech, there is an urgentdemand for better hate speech detection systems. In this paper, weutilize Knowledge Graphs (KGs) to improve hate speech detection.Our initial results shows that incorporating information from KG helps the classifier to improve the performance. ","tags":null,"title":"Using Knowledge Graphs to Improve Hate Speech Detection","type":"publication"},{"authors":["Binny Mathew","Punyajoy Saha","Seid Muhie Yimam","Chris Biemann","Pawan Goyal","Animesh Mukherjee"],"categories":null,"content":"","date":1608249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1608249600,"objectID":"7ea7584ff88a42ebe606db25c6da5388","permalink":"/publication/aaai_2021/","publishdate":"2020-12-18T00:00:00Z","relpermalink":"/publication/aaai_2021/","section":"publication","summary":"Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales, i.e., the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public","tags":null,"title":"HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection","type":"publication"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our paper \u0026ldquo;HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection\u0026rdquo; has been accepted as full paper at AAAI-21 . Joint work with Binny Mathew, Seid Muhie Yimam, Charis Biemann, Pawan Goyal and Animesh mukherjee. Check this twitter_link to know more. Paper and code will be out soon.\n","date":1606761000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606761000,"objectID":"05bc38ee0fa1c022e3e2118de1c52ca9","permalink":"/post/aaai21_accepted/","publishdate":"2020-12-01T00:00:00+05:30","relpermalink":"/post/aaai21_accepted/","section":"post","summary":"Our paper \u0026ldquo;HateXplain: A Benchmark Dataset for Explainable Hate Speech Detection\u0026rdquo; has been accepted as full paper at AAAI-21 . Joint work with Binny Mathew, Seid Muhie Yimam, Charis Biemann, Pawan Goyal and Animesh mukherjee. Check this twitter_link to know more. Paper and code will be out soon.","tags":[],"title":"Paper on Explainable hate speech dataset accepted at AAAI 2021","type":"post"},{"authors":["Punyajoy Saha"],"categories":[],"content":"We rank 11th in the world among more than 3000 participants , in a competition detecting hate meme - A competition organised by Facebook on Driven Data platform. More in this url\n","date":1603996200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603996200,"objectID":"f1564658946b5053f1d512203c255837","permalink":"/post/facebook_11th/","publishdate":"2020-10-30T00:00:00+05:30","relpermalink":"/post/facebook_11th/","section":"post","summary":"We rank 11th in the world among more than 3000 participants , in a competition detecting hate meme - A competition organised by Facebook on Driven Data platform. More in this url","tags":[],"title":"World rank 11th in Hatememe detection competition organised by Facebook","type":"post"},{"authors":["Binny Mathew","Anurag Illendula","Punyajoy Saha","Soumya Sarkar","Pawan Goyal","Animesh Mukherjee"],"categories":null,"content":"","date":1595635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595635200,"objectID":"f77ee4025bca24637e956ab4eaae01c2","permalink":"/publication/cscw_2020/","publishdate":"2020-07-25T00:00:00Z","relpermalink":"/publication/cscw_2020/","section":"publication","summary":"With the ongoing debate on ‘freedom of speech’ vs. ‘hate speech,’ there is an urgent need to carefullyunderstand the consequences of the inevitable culmination of the two, i.e., ‘freedom of hate speech’ over time.An ideal scenario to understand this would be to observe the effects of hate speech in an (almost) unrestricted environment. Hence, we perform the first temporal analysis of hate speech on Gab.com, a social media site with very loose moderation policy. We first generatetemporal snapshotsof Gab from millions of posts and users. Using these temporal snapshots, we compute anactivity vectorbased on DeGroot model to identify hateful users. The amount of hate speech in Gab is steadily increasing and the new users are becoming hatefulat an increased and faster rate. Further, our analysis analysis reveals that the hate users are occupying the prominent positions in the Gab network. Also, the language used by the community as a whole seem tocorrelate more with that of the hateful users as compared to the non-hateful ones. We discuss how, many crucial design questions in CSCW open up from our work.","tags":null,"title":"Hate begets Hate: A Temporal Study of Hate Speech","type":"publication"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our paper \u0026ldquo;Hate begets Hate: A Temporal Study of Hate Speech\u0026rdquo; got accepted at CSCW 2020. arXiv Draft\n","date":1595529000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595529000,"objectID":"8a227c875115cbeffa86117715a704cd","permalink":"/post/cscw_accepted/","publishdate":"2020-07-24T00:00:00+05:30","relpermalink":"/post/cscw_accepted/","section":"post","summary":"Our paper \u0026ldquo;Hate begets Hate: A Temporal Study of Hate Speech\u0026rdquo; got accepted at CSCW 2020. arXiv Draft","tags":[],"title":"Paper on temporal effects of hate speech got accepted in CSCW 2020","type":"post"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our organisation hate-alert got covered by the CEO of huggingface. We did a large scale analysis on multilingual hate speech detection using various state of the art models. Check our models here , our paper here. If you just want to check the inference go here.\n","date":1594751400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594751400,"objectID":"110478124ec9251db638e6b8095819a8","permalink":"/post/hate_alert_covered/","publishdate":"2020-07-15T00:00:00+05:30","relpermalink":"/post/hate_alert_covered/","section":"post","summary":"Our organisation hate-alert got covered by the CEO of huggingface. We did a large scale analysis on multilingual hate speech detection using various state of the art models. Check our models here , our paper here. If you just want to check the inference go here.","tags":[],"title":"Hate alert covered by Huggingface CEO in twitter","type":"post"},{"authors":["Punyajoy Saha"],"categories":[],"content":"Our Paper got accepted ECMLPKDD 2020. Check our models here , our paper here\n","date":1592591400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592591400,"objectID":"892399ad8b7327eefecc0a5f2939937f","permalink":"/post/ecml-pkdd-accepted/","publishdate":"2020-06-20T00:00:00+05:30","relpermalink":"/post/ecml-pkdd-accepted/","section":"post","summary":"Our Paper got accepted ECMLPKDD 2020. Check our models here , our paper here","tags":[],"title":"Paper on multilingual hate speech detection accepted at ECML PKDD 2020","type":"post"},{"authors":[],"categories":[],"content":"We won the data grant from facebook + social science one which comes with a huge amount(1 trillion!!) of urls and their metadata from facebook under a differential privacy regime.\n","date":1587321000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587321000,"objectID":"9c99248bd1a1ddc7c203161f6d5e4167","permalink":"/post/facebook_data_grant/","publishdate":"2020-04-20T00:00:00+05:30","relpermalink":"/post/facebook_data_grant/","section":"post","summary":"We won the data grant from facebook + social science one which comes with a huge amount(1 trillion!!) of urls and their metadata from facebook under a differential privacy regime.","tags":[],"title":"Winner of Facebook and Social Science One data grant","type":"post"},{"authors":["Sai Saketh Aluru","Binny Mathews","Punyajoy Saha","Animesh Mukherjee"],"categories":null,"content":"","date":1586908800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586908800,"objectID":"683ae68cb6d1fa0f050a93d8666fe58f","permalink":"/publication/ecml_pkdd_2020/","publishdate":"2020-04-15T00:00:00Z","relpermalink":"/publication/ecml_pkdd_2020/","section":"publication","summary":"Hate speech detection is a challenging problem with most of the datasets available in only one language: English. In this paper, we conduct a large scale analysis of multilingual hate speech in 9 languages from 16 different sources. We observe that in low resource setting, simple models such as LASER embedding with logistic regression performs the best, while in high resource setting BERT based models perform better. In case of zero-shot classification, languages such as Italian and Portuguese achieve good results. Our proposed framework could be used as an efficient solution for low-resource languages. These models could also act as good baselines for future multilingual hate speech detection tasks.","tags":null,"title":"Deep Learning Models for Multilingual Hate Speech Detection","type":"publication"},{"authors":["Punyajoy Saha"],"categories":[],"content":"❤\n","date":1577903400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577903400,"objectID":"079c702843f283aded452d177a268b7e","permalink":"/post/entered_phd/","publishdate":"2020-01-02T00:00:00+05:30","relpermalink":"/post/entered_phd/","section":"post","summary":"❤","tags":["Education"],"title":"Joined PhD in January 2020","type":"post"},{"authors":[],"categories":[],"content":"Our work in misogyny detection get recognised by MIT Technical Review here\n","date":1577557800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577557800,"objectID":"accd54872389dcf21935ac4d9a834699","permalink":"/post/best_preprint/","publishdate":"2019-12-29T00:00:00+05:30","relpermalink":"/post/best_preprint/","section":"post","summary":"Our work in misogyny detection get recognised by MIT Technical Review ![here](https://www.technologyreview.com/2018/12/29/138019/the-best-of-the-physics-arxiv-week-ending-december-29-2018/)","tags":[],"title":"Misogyny detection recognised by MIT Technical Review","type":"post"},{"authors":["Punyajoy Saha","Binny Mathews","Animesh Mukherjee","Pawan Goyal"],"categories":null,"content":"","date":1576368000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576368000,"objectID":"4595118dfc1b3d1a2911ea1a4dad0a17","permalink":"/publication/hasoc_2019/","publishdate":"2019-12-15T00:00:00Z","relpermalink":"/publication/hasoc_2019/","section":"publication","summary":"Reducing hateful and offensive content in online social media  pose  a  dual  problem  for  the  moderators.  On  the  one  hand,  rigid censorship  on  social  media  cannot  be  imposed.  On  the  other,  the free flow of such content cannot be allowed. Hence, we require efficient abusive language detection system to detect such harmful content in socialmedia. In this paper, we present our machine learning model, HateMonitor, developed for Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC), a shared task at FIRE 2019.W e have used Gradient Boosting model, along with BERT and LASER embeddings,  to  make  the  system  language  agnostic.  Our  model  cameatFirst positionfor the German sub-task A.","tags":null,"title":"HateMonitors: Language Agnostic Abuse Detection in Social Media","type":"publication"},{"authors":["Binny Mathews","Punyajoy Saha","Hardik Tharad","Subham Rajgaria","Prajwal Singhania","Suman Kalyan Maity","Animesh Mukherjee","Pawan Goyal"],"categories":null,"content":"","date":1560384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560384000,"objectID":"8957b339c5a95d7e04133c0e32f5f384","permalink":"/publication/icwsm_2019/","publishdate":"2019-06-13T00:00:00Z","relpermalink":"/publication/icwsm_2019/","section":"publication","summary":"Hate content in social media is ever increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. Lack of carefully curated data largely inhibits such understanding. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 13,924 manually annotated comments where the labels indicate whether a comment is a counterspeech or not. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the noncounterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.71. We also build multilabel models that can detect different types of counterspeech in a comment with an F1-score of 0.60.","tags":null,"title":"Thou shalt not hate: Countering Online Hate Speech","type":"publication"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Punyajoy Saha","Binny Mathews","Animesh Mukherjee","Pawan Goyal"],"categories":null,"content":"","date":1543881600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543881600,"objectID":"0d9ddae9c6344d7d6d98db91e0eaa09a","permalink":"/publication/evalita_ami_2018/","publishdate":"2018-12-04T00:00:00Z","relpermalink":"/publication/evalita_ami_2018/","section":"publication","summary":"With the online proliferation of hate speech, there is an urgent need for systems that can detect such harmful content. In this paper, We present the machine learning models developed for the Automatic Misogyny Identification (AMI) shared task at EVALITA 2018. We generate three types of features: Sentence Embeddings, TF-IDF Vectors, and BOW Vectors to represent each tweet. These features are then concatenated and fed into the machine learning models. Our model came First for the English Subtask A and Fifth for the English Subtask B. We release our winning model for public use.","tags":null,"title":"Hateminers: Detecting Hatespeech against Women","type":"publication"},{"authors":["Chetan Ralekar","Punyajoy Saha","Tapan K. Gandhi","Santanu Chaudhury"],"categories":null,"content":"","date":1541808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541808000,"objectID":"40389da526977d6e569a080d6551393b","permalink":"/publication/ihci_2018/","publishdate":"2018-11-10T00:00:00Z","relpermalink":"/publication/ihci_2018/","section":"publication","summary":"In this world of digitization, screen reading has grown immensely due to the availability of affordable display devices. Most of the people prefer to read on display devices as compared to the print media. To make the reading experience of the reader pleasant and comfortable, the font designers strive hard to choose suitable typographical properties of the text such as font type, font size etc. Some of the researchers suggest that the typography of the text affects the reading performance of the readers to some extent. However, the research focusing on the effect of typography on the reading behavior of the readers is limited and it is hardly touched upon for the Indian scripts. Therefore, the proposed paper aims to find out the effect of Devanagari font type on the reading performance, especially reading comprehension of the readers. In addition to this, a method to reduce the error in the gaze estimation of the eye tracker is also proposed. In order to understand the reading behavior, an eye tracking experiment is performed on 14 participants asking them to read 22 pages, in 3 different font types, presented on the screen of the eye tracker. The performance of the readers is analyzed in terms of total reading time, comprehension score, number of fixations, fixation duration and number of regressions. Our results show that there is a significant difference in the fixation duration, a number of fixations and the comprehension score, when the same document is read in different font type. Thus, there is a scope for improvement in the reading comprehension, by changing the physical properties of the document without changing its content. These findings might be useful to understand the readers’ preference for the font and to design a proper font type for online reading.","tags":null,"title":"Effect of Devanagari Font Type in Reading Comprehension: An Eye Tracking Study","type":"publication"},{"authors":["Sandipan Sarma","Punyajoy Saha","Jaya Sil"],"categories":null,"content":"","date":1524268800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524268800,"objectID":"652cbc8ea497897780af961dc10f0bd7","permalink":"/publication/iccacp_2018/","publishdate":"2018-04-21T00:00:00Z","relpermalink":"/publication/iccacp_2018/","section":"publication","summary":"This paper proposes a document classification model using feature learning approach based on semantics of the documents. In the learning phase, basic vocabulary (BV) for each document class consisting of nouns has been created by proposing a novel approach. The classification phase searches unique words in the BVs and if found, the corresponding sentence becomes a basic sentence (BS). A tree with unique words of the BS is inserted in the respective forest. Associated words of the children are used to continue the tree formation process until no new node is generated in the tree. Finally, we assign the test document to a class which has a clearly dominant percentage of sentences in the respective forest. The proposed algorithm is compared with various feature-based classification models and satisfactory performance has been observed.","tags":null,"title":"Document Categorization Using Graph Structuring","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"}]